query_tokenizer:
  init:
    language_model: ${language_model.name}
    max_len: 16
    add_prefix_token: true

doc_tokenizer:
  init:
    language_model: ${language_model.name}
    max_len: 128
    add_prefix_token: true
